{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Decision Tree algorithm I built previously as the foundation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gini Impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gini(x): \n",
    "    counter = Counter(x)\n",
    "    total = len(x)\n",
    "    G = 0\n",
    "    for value in counter.values():\n",
    "        prob = value/total\n",
    "        G += prob * (1 - prob)\n",
    "    return G\n",
    "\n",
    "def weighted_gini(a, b):\n",
    "    return (len(a) * gini(a) + len(b) * gini(b))/(len(a) + len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identical_values(x):\n",
    "    test_val = x[0]\n",
    "    if all(x == test_val):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Used to find the optimal split within a continuous measurement\n",
    "\n",
    "def split_cont_measure(data, target):\n",
    "    data = np.array(data)\n",
    "    \n",
    "    # sorting the data to find the mid values\n",
    "    idx = np.argsort(data)\n",
    "    sorted_data = data[idx]\n",
    "    \n",
    "    past_x = sorted_data[0]\n",
    "    middle_values = [] \n",
    "    for x in sorted_data: \n",
    "        if x != past_x:\n",
    "            average_x = 0.5 * (x + past_x)\n",
    "            middle_values.append(average_x)\n",
    "            past_x = x\n",
    "    \n",
    "    # Finding the gini for each split\n",
    "    gini_values = np.zeros(len(middle_values))    \n",
    "    \n",
    "    for i, mid_val in enumerate(middle_values):\n",
    "        smaller_idx = data < mid_val\n",
    "        larger_idx = np.invert(smaller_idx)\n",
    "        \n",
    "        g = weighted_gini(target[smaller_idx], target[larger_idx])\n",
    "        gini_values[i] = g \n",
    "    \n",
    "    # Choosing the best split based on gini value\n",
    "    best_split = middle_values[np.argmin(gini_values)]\n",
    "    return best_split, np.min(gini_values)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Used to find the optimal split within a discrete measurement\n",
    "def split_disc_measures(data, target):\n",
    "    data = np.array(data)\n",
    "    \n",
    "    distinct_data = np.unique(data)\n",
    "    gini_values = np.zeros(len(distinct_data))\n",
    "    \n",
    "    for i, x in enumerate(distinct_data):\n",
    "        match = data == x\n",
    "        other = data != x\n",
    "        \n",
    "        match_t = target[match]\n",
    "        other_t = target[other]\n",
    "    \n",
    "        gini_values[i] = weighted_gini(match_t, other_t) \n",
    "        \n",
    "    best = np.argmin(gini_values)\n",
    "    return distinct_data[best], gini_values[best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_probability(targets):\n",
    "    counts = Counter(targets).most_common()\n",
    "    total = len(targets)\n",
    "    results = []\n",
    "    for key, val in counts:\n",
    "        results.append([key, val/total])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \n",
    "    def __init__(self, data, target, min_node_size = 5):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.node_gini = gini(self.target)\n",
    "        self.node_type = \"node\"\n",
    "        self.min_node_size = min_node_size\n",
    "        self.branch_left = None\n",
    "        self.branch_right = None \n",
    "        self.measurement_idx = None \n",
    "        self.split_value = None \n",
    "        self.split_method = None\n",
    "    \n",
    "    \n",
    "                \n",
    "    def train(self):\n",
    "        if self.min_node_size >= len(self.data):\n",
    "            self.node_type = \"leaf\"\n",
    "        \n",
    "        else:\n",
    "            split_values = np.zeros(len(self.data.T))\n",
    "            gini_values = np.zeros(len(self.data.T))\n",
    "            methods = []\n",
    "\n",
    "            for i, measure in enumerate(self.data.T):\n",
    "                \n",
    "                if identical_values(measure): \n",
    "                    gini_values[i] = 1 # Prevents the algorithm from trying to split a group of identical values\n",
    "                    methods.append(\"FalseSplit\")\n",
    "                # If measurement is discrete\n",
    "                elif type(measure[0]) == np.str_:\n",
    "                    split_values[i], gini_values[i] = split_disc_measures(measure, self.target)\n",
    "                    methods.append(\"=\")\n",
    "\n",
    "                # If measurement is continuous\n",
    "                else:\n",
    "                    split_values[i], gini_values[i] = split_cont_measure(measure, self.target)\n",
    "                    methods.append(\"<\")\n",
    "\n",
    "            best = self.measurement_idx = np.argmin(gini_values)\n",
    "            self.split_value = split_values[best]\n",
    "            self.split_method = methods[best]\n",
    "\n",
    "            # If the split does not improve gini impurity -> make leaf node\n",
    "            if gini_values[best] >= self.node_gini:\n",
    "                self.node_type = \"leaf\"\n",
    "\n",
    "            # Else split into two new nodes and repeat function \n",
    "            else: \n",
    "                if self.split_method == \"=\":\n",
    "                    left_idx = self.data.T[best] == split_values[best]\n",
    "                    right_idx = self.data.T[best] != split_values[best]\n",
    "                else: \n",
    "                    left_idx = self.data.T[best] < split_values[best]\n",
    "                    right_idx = self.data.T[best] >= split_values[best]\n",
    "                \n",
    "                \n",
    "                # checking that neither of the branches are empty\n",
    "                if len(left_idx) == 0 or len(right_idx) == 0:\n",
    "                    self.node_type = \"leaf\"\n",
    "\n",
    "                else:\n",
    "                    self.branch_left = Node(self.data[left_idx], self.target[left_idx])\n",
    "                    self.branch_right = Node(self.data[right_idx], self.target[right_idx])\n",
    "\n",
    "                    self.branch_left.train()\n",
    "                    self.branch_right.train()\n",
    "\n",
    "                    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def predict(self, query, style = \"classification\"):\n",
    "        if self.node_type == \"leaf\":\n",
    "            counter = Counter(self.target)\n",
    "\n",
    "            if style == \"regression\": \n",
    "                return find_probability(self.target)\n",
    "\n",
    "            else: # classification\n",
    "                most_common = find_probability(self.target)[0][0]\n",
    "                return most_common\n",
    "            \n",
    "        # If not end of branch\n",
    "        else: \n",
    "            query_val = query[self.measurement_idx]\n",
    "            \n",
    "            if self.split_method == \"=\":\n",
    "                if query_val == self.split_value:\n",
    "                    return left_branch.predict(query, style = style)\n",
    "                else: \n",
    "                    return right_branch.predict(query, style = style)\n",
    "                \n",
    "            else: \n",
    "                if query_val < self.split_value:\n",
    "                    return self.branch_left.predict(query, style = style)\n",
    "                else: \n",
    "                    return self.branch_right.predict(query, style = style)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = Node(x_train, y_train)\n",
    "dt.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = np.zeros(len(x_test))\n",
    "for i, x in enumerate(x_test):\n",
    "    predictions[i] = dt.predict(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97999999999999998"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(predictions == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Creating a Random Forest out of Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_subset(x, num_data, replace = True):\n",
    "    data_idx = np.arange(len(x))\n",
    "    subset_idx = np.random.choice(data_idx, num_data, replace)\n",
    "    subset_x = x[subset_idx]\n",
    "    return subset_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_feature_selection(x, y):\n",
    "    # Bootstrapping the data\n",
    "    num_data = len(x)\n",
    "    data_idx = np.arange(num_data)\n",
    "    subset_idx = np.random.choice(data_idx, num_data, replace = True)\n",
    "    subset_x = x[subset_idx]\n",
    "    subset_y = y[subset_idx]\n",
    "    \n",
    "    # Random selection of features\n",
    "    num_features = len(x.T)\n",
    "    feature_idx = np.arange(num_features)\n",
    "    subset_idx = np.random.choice(feature_idx, int(np.sqrt(num_features)), replace = False)\n",
    "    subset_x = x.T[subset_idx]\n",
    "    \n",
    "    return subset_x.T, subset_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Random_Forest:\n",
    "    def __init__(self, data, target, min_node_size = 5, num_trees = 50):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.forest = []\n",
    "        for tree in range(num_trees):\n",
    "            data_subset, target_subset = data_feature_selection(self.data, self.target)\n",
    "            self.forest.append(Node(data_subset, target_subset))\n",
    "\n",
    "    def train(self):\n",
    "        for tree in self.forest:\n",
    "            tree.train()\n",
    "    \n",
    "    def predict(self, query_data, style = \"classification\"):\n",
    "        self.predictions = np.arange(num_trees)\n",
    "        for i, tree in enumerate(self.forest): \n",
    "            #self.predictions[i] = tree.predict(query_data, style)\n",
    "            print(tree.predict(query_data, style))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trial = Random_Forest(x_train, y_train)\n",
    "trial.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
