{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from collections import Counter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
      "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
      "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
      "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
      "\n",
      "   ca  thal  target  \n",
      "0   0     1       1  \n",
      "1   0     2       1  \n",
      "2   0     2       1  \n"
     ]
    }
   ],
   "source": [
    "heart = pd.read_csv(\"heart.csv\")\n",
    "print(heart.head(3))\n",
    "heart_data = heart.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(heart_data)\n",
    "X = heart_data[:, :-1]\n",
    "Y = heart_data[:, -1]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Decision Tree algorithm I built previously as the foundation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gini Impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gini(x): \n",
    "    counter = Counter(x)\n",
    "    total = len(x)\n",
    "#    G = 0\n",
    "#    for value in counter.values():\n",
    "#        prob = value/total\n",
    "#        G += prob * (1 - prob)\n",
    "#    return G\n",
    "    GI = 1 \n",
    "    for value in counter.values():\n",
    "        prob = value/total \n",
    "        GI -= prob**2\n",
    "    return GI\n",
    "\n",
    "\n",
    "def weighted_gini(a, b):\n",
    "    return (len(a) * gini(a) + len(b) * gini(b))/(len(a) + len(b))\n",
    "\n",
    "def information_gain(original_data, data_left, data_right):\n",
    "    \n",
    "    pL = len(data_left)/len(original_data)\n",
    "    pR = len(data_right)/len(original_data)\n",
    "    \n",
    "    return gini(original_data) - pL * gini(data_left) - pR * gini(data_right)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identical_values(x):\n",
    "    test_val = x[0]\n",
    "    if all(x == test_val):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Used to find the optimal split within a continuous measurement\n",
    "\n",
    "def split_cont_measure(data, target):\n",
    "    data = np.array(data)\n",
    "    \n",
    "    # sorting the data to find the mid values\n",
    "    idx = np.argsort(data)\n",
    "    sorted_data = data[idx]\n",
    "    \n",
    "    past_x = sorted_data[0]\n",
    "    middle_values = [] \n",
    "    for x in sorted_data: \n",
    "        if x != past_x:\n",
    "            average_x = 0.5 * (x + past_x)\n",
    "            middle_values.append(average_x)\n",
    "            past_x = x\n",
    "    \n",
    "    # Finding the gini for each split\n",
    "    info_gain = np.zeros(len(middle_values))    \n",
    "    \n",
    "    for i, mid_val in enumerate(middle_values):\n",
    "        smaller_idx = data < mid_val\n",
    "        larger_idx = np.invert(smaller_idx)\n",
    "        \n",
    "        #g = weighted_gini(target[smaller_idx], target[larger_idx])\n",
    "        info_gain[i] = information_gain(target, target[smaller_idx], target[larger_idx]) \n",
    "    \n",
    "    # Choosing the best split based on gini value\n",
    "    best_split = middle_values[np.argmax(info_gain)]\n",
    "    return best_split, np.max(info_gain)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Used to find the optimal split within a discrete measurement\n",
    "def split_disc_measures(data, target):\n",
    "    data = np.array(data)\n",
    "    \n",
    "    distinct_data = np.unique(data)\n",
    "    info_gain = np.zeros(len(distinct_data))\n",
    "    \n",
    "    for i, x in enumerate(distinct_data):\n",
    "        match = data == x\n",
    "        other = data != x\n",
    "        \n",
    "        match_t = target[match]\n",
    "        other_t = target[other]\n",
    "    \n",
    "        info_gain[i] = information_gain(target, match_t, other_t) \n",
    "        \n",
    "    best = np.argmax(info_gain)\n",
    "    return distinct_data[best], info_gain[best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_probability(targets):\n",
    "    counts = Counter(targets).most_common()\n",
    "    total = len(targets)\n",
    "    results = []\n",
    "    for key, val in counts:\n",
    "        results.append([key, val/total])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mode(x):\n",
    "    return find_probability(x)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \n",
    "    def __init__(self, data, target, min_node_size = 5):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.node_gini = gini(self.target)\n",
    "        self.node_type = \"node\"\n",
    "        self.min_node_size = min_node_size\n",
    "        self.branch_left = None\n",
    "        self.branch_right = None \n",
    "        self.measurement_idx = None \n",
    "        self.split_value = None \n",
    "        self.split_method = None\n",
    "                \n",
    "    def train(self):\n",
    "        if self.min_node_size >= len(self.data):\n",
    "            self.node_type = \"leaf\"\n",
    "        \n",
    "        else:\n",
    "            split_values = np.zeros(len(self.data.T))\n",
    "            info_gain = np.zeros(len(self.data.T))\n",
    "            methods = []\n",
    "\n",
    "            for i, measure in enumerate(self.data.T):\n",
    "                \n",
    "                if identical_values(measure): \n",
    "                    info_gain[i] = 0 # Prevents the algorithm from trying to split a group of identical values\n",
    "                    methods.append(\"FalseSplit\")\n",
    "                \n",
    "                # If measurement is discrete\n",
    "                elif type(measure[0]) == np.str_:\n",
    "                    split_values[i], info_gain[i] = split_disc_measures(measure, self.target)\n",
    "                    methods.append(\"=\")\n",
    "\n",
    "                # If measurement is continuous\n",
    "                else:\n",
    "                    split_values[i], info_gain[i] = split_cont_measure(measure, self.target)\n",
    "                    methods.append(\"<\")\n",
    "            \n",
    "            best = self.measurement_idx = np.argmax(info_gain)\n",
    "            self.split_value = split_values[best]\n",
    "            self.split_method = methods[best]\n",
    "\n",
    "            # If the split does not provide any more information -> make leaf node\n",
    "            if info_gain[best] == 0: \n",
    "                self.node_type = \"leaf\"\n",
    "\n",
    "            # Else split into two new nodes and repeat function \n",
    "            else: \n",
    "                if self.split_method == \"=\":\n",
    "                    left_idx = self.data.T[best] == split_values[best]\n",
    "                    right_idx = self.data.T[best] != split_values[best]\n",
    "                else: \n",
    "                    left_idx = self.data.T[best] < split_values[best]\n",
    "                    right_idx = self.data.T[best] >= split_values[best]\n",
    "                \n",
    "                \n",
    "                # checking that neither of the branches are empty\n",
    "                if len(left_idx) == 0 or len(right_idx) == 0:\n",
    "                    self.node_type = \"leaf\"\n",
    "\n",
    "                else:\n",
    "                    self.branch_left = Node(self.data[left_idx], self.target[left_idx])\n",
    "                    self.branch_right = Node(self.data[right_idx], self.target[right_idx])\n",
    "\n",
    "                    self.branch_left.train()\n",
    "                    self.branch_right.train()\n",
    "    \n",
    "    \n",
    "    def predict(self, query, style = \"c\"):\n",
    "        if self.node_type == \"leaf\":\n",
    "            counter = Counter(self.target)\n",
    "\n",
    "            if style == \"r\": \n",
    "                return find_probability(self.target)\n",
    "\n",
    "            else: # classification\n",
    "                most_common = mode(self.target)\n",
    "                return most_common\n",
    "            \n",
    "        # If not end of branch\n",
    "        else: \n",
    "            query_val = query[self.measurement_idx]\n",
    "            \n",
    "            if self.split_method == \"=\":\n",
    "                if query_val == self.split_value:\n",
    "                    return left_branch.predict(query, style = style)\n",
    "                else: \n",
    "                    return right_branch.predict(query, style = style)\n",
    "                \n",
    "            else: \n",
    "                if query_val < self.split_value:\n",
    "                    return self.branch_left.predict(query, style = style)\n",
    "                else: \n",
    "                    return self.branch_right.predict(query, style = style)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = Node(x_train, y_train)\n",
    "dt.train()\n",
    "predictions = np.zeros(len(x_test))\n",
    "for i, x in enumerate(x_test):\n",
    "    predictions[i] = dt.predict(x)\n",
    "np.average(predictions == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Creating a Random Forest out of Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_subsample(x, y):\n",
    "    # Bootstrapping the data\n",
    "    num_data = len(x)\n",
    "    data_idx = np.arange(num_data)\n",
    "    subset_idx = np.random.choice(data_idx, num_data, replace = True)\n",
    "    subset_x = x[subset_idx]\n",
    "    subset_y = y[subset_idx]\n",
    "    \n",
    "    return subset_x, subset_y\n",
    "\n",
    "def feature_selection(x):\n",
    "    # Random selection of features\n",
    "    num_features = len(x.T)\n",
    "    feature_idx = np.arange(num_features)\n",
    "    subset_idx = np.random.choice(feature_idx, int(np.sqrt(num_features)), replace = False)\n",
    "    x = x.T[subset_idx].T\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]\n",
      " [15 16 17 18 19]\n",
      " [20 21 22 23 24]\n",
      " [25 26 27 28 29]\n",
      " [30 31 32 33 34]\n",
      " [35 36 37 38 39]\n",
      " [40 41 42 43 44]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(45).reshape(9, 5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialise_forest(data, target, min_node_size, num_trees):\n",
    "    forest = []\n",
    "    for tree in range(num_trees):\n",
    "        data_subset, target_subset = data_subsample(data, target)\n",
    "        data_subset = feature_selection(data_subset)\n",
    "        forest.append(Node(data_subset, target_subset, min_node_size))\n",
    "    return forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Random_Forest:\n",
    "    def __init__(self, data, target, min_node_size = 1, num_trees = 100):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.num_trees = num_trees\n",
    "        self.forest = initialise_forest(data, target,  min_node_size, num_trees)\n",
    "\n",
    "    def train(self):\n",
    "        for tree in self.forest:\n",
    "            tree.train()\n",
    "    \n",
    "    def predict(self, query_data, style = \"c\"):\n",
    "        predictions = np.arange(self.num_trees)\n",
    "\n",
    "        for i, tree in enumerate(self.forest): \n",
    "            pred = tree.predict(query_data, style)\n",
    "            predictions[i] = pred \n",
    "            \n",
    "        most_common = mode(predictions)\n",
    "        return most_common\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trial = Random_Forest(x_train, y_train, num_trees = 100)\n",
    "trial.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trial_predictions = np.zeros(len(x_test))\n",
    "for i, query in enumerate(x_test):\n",
    "    trial_predictions[i] = trial.predict(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42\n"
     ]
    }
   ],
   "source": [
    "success = np.average(trial_predictions == y_test)\n",
    "print(success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
